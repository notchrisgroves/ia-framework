# DSA-Compliant Child Safety Policy Template
## Article 38: Protection of Minors

**Policy Type:** Child Safety & Minor Protection Policy
**DSA Article Covered:** Article 38 (primary), also supports Articles 34-35 (Risk Assessment - Minor Protection)
**Target Services:** All VLOP/VLOSE services accessible to minors
**Template Version:** 1.0
**Last Updated:** 2025-12-02

---

## How to Use This Template

1. **Fill in all [bracketed] fields** with service-specific information
2. **Keep all 8 components** - required for DSA compliance
3. **Customize age-appropriate measures** to match your service's child safety risks
4. **Translate to all 24 EU languages** before publication
5. **Review readability** - Use language appropriate for parents AND teens (grade level ≤8 for sections minors will read)
6. **Legal + child safety expert review** required before publication
7. **Update when features change** - Any new feature must be assessed for child safety impact

**DSA Requirements Checklist:**
- [ ] Age verification system implemented
- [ ] Parental consent process (if service has users under 16)
- [ ] Targeted advertising restrictions for minors in place
- [ ] Addictive design features assessed and mitigated
- [ ] Age-appropriate content controls implemented
- [ ] Privacy-by-design for minors (data minimization)
- [ ] Easy reporting for child abuse content
- [ ] Transparency about how minors are treated differently

---

# [SERVICE NAME] Child Safety Policy
## Protecting Minors on Our Platform

**Effective for all users under 18 in the European Union**

---

## COMPONENT 1: Metadata

**Policy Version:** [Version number - e.g., 3.0]

**Effective Date:** [Date]

**Last Updated:** [Date]

**Next Scheduled Review:** [Date - recommended: quarterly]

**Responsible Owner:**
- **Executive Sponsor:** [C-Level - e.g., Chief Trust & Safety Officer]
- **Policy Owner:** [VP / Director of Child Safety]
- **Implementation Team:** [Trust & Safety, Product, Engineering, Legal, Research]

**Policy Scope:** This policy applies to:
- **Users:** All users under 18 years old in the European Union
- **Service:** [SERVICE NAME]
- **Features:** [ALL / LIST SPECIFIC FEATURES if some are adults-only]

**Regulatory Basis:**
- EU Digital Services Act (Regulation 2022/2065), Article 38
- UN Convention on the Rights of the Child
- GDPR Article 8 (Child consent for information society services)
- ePrivacy Directive (2002/58/EC)
- EUR-Lex Reference: https://eur-lex.europa.eu/eli/reg/2022/2065

**Change History:**
| Version | Date | Changes | Approver |
|---------|------|---------|----------|
| [1.0] | [Date] | Initial child safety policy | [Name] |
| [2.0] | [Date] | Added parental controls, age verification | [Name] |
| [3.0] | [Date] | DSA Article 38 compliance updates | [Name] |

**Languages Available:**
This policy is available in all 24 official EU languages. See [URL] for translations.

---

## COMPONENT 2: Purpose & Scope

### Policy Purpose

**Our Commitment:**

[SERVICE NAME] is committed to providing a safe online environment for children and adolescents. This policy explains:

- **How we verify ages** to ensure age-appropriate experiences
- **How parents can control** their child's account (for users under 16)
- **How we restrict advertising** to minors (no profiling-based targeting)
- **How we design responsibly** to avoid addictive or harmful features for minors
- **How we protect privacy** (data minimization, no selling minor data)
- **How to report** child abuse content or predatory behavior
- **How minor accounts differ** from adult accounts

**Why This Matters:**

Children and adolescents are more vulnerable online. They may:
- Not recognize manipulation, scams, or predatory behavior
- Be more susceptible to harmful content (violence, eating disorders, self-harm)
- Struggle with excessive use and addictive design patterns
- Not understand privacy risks and data collection

We design [SERVICE NAME] to reduce these risks while enabling minors to safely [BENEFIT - e.g., "learn, create, connect with friends"].

### Who This Policy Covers

**Age Definitions:**

- **Children (Under 13):**
  - [SERVICE DOES NOT ALLOW / ALLOWS WITH RESTRICTIONS]
  - If allowed: [DESCRIBE RESTRICTIONS - e.g., "Can only access parent-controlled content catalog"]

- **Young Adolescents (Ages 13-15):**
  - Parental consent required (GDPR Article 8 + DSA Article 38)
  - [DESCRIBE EXPERIENCE - e.g., "Private accounts by default, limited contact from adults, no targeted ads"]

- **Older Adolescents (Ages 16-17):**
  - Can use service independently (no parental consent required)
  - Still receive minor-specific protections: [LIST - e.g., "No targeted ads, limited data collection, age-appropriate content"]

**Note:** Some EU member states set digital age of consent below 16. We apply the [MOST / LEAST] protective standard across the EU. [SPECIFY - e.g., "All users under 16 need parental consent regardless of national law"]

### Geographic Scope

**EU Member States:** Austria, Belgium, Bulgaria, Croatia, Cyprus, Czech Republic, Denmark, Estonia, Finland, France, Germany, Greece, Hungary, Ireland, Italy, Latvia, Lithuania, Luxembourg, Malta, Netherlands, Poland, Portugal, Romania, Slovakia, Slovenia, Spain, Sweden

**Outside EU:** For users outside the EU, see our standard Child Safety Policy at [URL]

### What This Policy Covers

✅ **Included:**
- Age verification methods
- Parental consent & control systems
- Advertising restrictions for minors
- Design features and addictive pattern mitigation
- Content restrictions (what minors can/cannot see)
- Privacy protections for minors
- Contact restrictions (who can message minors)
- Reporting and safety tools

❌ **Not Included (See Separate Policies):**
- Content moderation (all users) → [Content Policy URL]
- Privacy and data processing → [Privacy Policy URL]
- Terms of Service → [TOS URL]

---

## COMPONENT 3: Age Verification & Parental Consent

### Age Verification System

**Why We Verify Ages:**

To provide age-appropriate experiences, we need to know how old you are. We use age verification to:
- Prevent children under [MINIMUM AGE] from creating accounts
- Apply minor-specific protections for users under 18
- Enable parental controls for users under 16

**How We Verify Ages:**

[SELECT YOUR VERIFICATION METHOD(S):]

☐ **Self-Reported Age (Basic):**
   - Users enter birthdate during signup
   - **Limitations:** Users may lie about age
   - **Enforcement:** We use behavioral signals and user reports to detect underage users
   - **If caught lying:** Account suspended until valid ID provided

☐ **Document Verification (Moderate):**
   - Users under 18 must verify age with [ID TYPE - e.g., "government ID, birth certificate"]
   - Verification provider: [THIRD PARTY - e.g., "Yoti, Veriff"]
   - Documents deleted after verification: [YES/NO, TIMEFRAME]

☐ **Age Estimation Technology (Advanced):**
   - AI-based age estimation using [METHOD - e.g., "facial analysis, behavioral patterns"]
   - Accuracy: [PERCENTAGE]% within [RANGE - e.g., "2 years"]
   - Human review: [YES/NO] for borderline cases
   - Privacy: [DESCRIBE - e.g., "Images not stored, processed on-device"]

☐ **Parental Email Verification (For Under-16s):**
   - Parent provides email address
   - Parent receives verification link
   - Parent must approve account creation

**Age Verification Frequency:**

- **At Signup:** All new users verify age
- **Ongoing:** We periodically re-verify if [TRIGGERS - e.g., "user behavior suggests incorrect age, user reports, major birthday (13, 16, 18)"]
- **Feature Access:** Age verification required before accessing [FEATURES - e.g., "live streaming, direct messaging, adult content"]

### Parental Consent (For Users Under 16)

**GDPR Requirement:**

Users under 16 (or lower national threshold) need **verifiable parental consent** for data processing.

**How Parental Consent Works:**

1. **Minor Provides Parent's Email:** Child enters parent/guardian email during signup
2. **We Email Parent:** Parent receives consent request explaining:
   - What service child wants to use
   - What data will be collected
   - How data will be used
   - Parental control options
3. **Parent Reviews & Approves:** Parent clicks link, reviews information, approves or denies
4. **Account Activated:** If approved, child's account is activated with parental oversight
5. **Parent Can Revoke:** Parent can withdraw consent anytime at [URL]

**What If Parent Doesn't Consent:**

- Child cannot create account
- Alternative: [IF APPLICABLE - e.g., "Child can use limited 'Kids Mode' with no data collection"]

### Parental Control Dashboard

**For children under 16, parents get a control dashboard at [URL]:**

**Usage Monitoring:**
☐ View screen time (daily, weekly reports)
☐ See what child is viewing/posting
☐ Review contacts (who child is communicating with)

**Controls:**
☐ Set daily time limits (e.g., 2 hours per day)
☐ Schedule "Quiet Time" (disable service during school, bedtime)
☐ Approve friend/follow requests
☐ Content filters (restrict by [CRITERIA - e.g., "age rating, content type, keywords"])

**Safety:**
☐ Restrict direct messages (no DMs from strangers)
☐ Limit who can comment on posts
☐ Hide child's profile from search
☐ Receive alerts for [TRIGGERS - e.g., "flagged content, new contacts, changes to privacy settings"]

**Account Management:**
☐ Download child's data
☐ Delete child's account
☐ Transfer account to child (when turns 16)
☐ Withdraw consent (deactivate account)

---

## COMPONENT 4: Advertising Restrictions

**DSA Article 38(2): No profiling-based advertising to minors**

### What This Means

**Prohibited for Minors:**
- ❌ **Targeted advertising based on profiling** - We cannot show ads based on your:
  - Browsing history
  - Search history
  - Interests inferred from behavior
  - Location (beyond country-level)
  - Social connections
  - Any personal data collection

**Allowed for Minors:**
- ✅ **Contextual advertising** - Ads related to the content you're viewing right now (not based on your personal profile)
- ✅ **General demographic targeting** - Age and country only (e.g., "Show this ad to 13-17 year olds in France")
- ✅ **First-party ads** - Ads for [SERVICE NAME]'s own products/features

### Restricted Ad Categories

**Minors will NEVER see ads for:**

[SELECT ALL THAT APPLY:]

☐ Alcohol
☐ Gambling / Betting
☐ Tobacco / Vaping
☐ Cannabis / Drugs
☐ Weapons
☐ Cosmetic Surgery
☐ Weight Loss Products / Diet Pills
☐ Dating Services
☐ Financial Services (loans, credit cards, crypto)
☐ Political Advertising
☐ [OTHER RESTRICTED CATEGORIES]

### Age-Appropriate Advertising

**For users 13-17, we [DO / DO NOT] show ads.**

**If ads are shown:**
- Ads are contextual only (based on current content, not user profile)
- Ads are from [RESTRICTED CATEGORIES - e.g., "education, entertainment, age-appropriate products"]
- Ads do not encourage [BEHAVIORS - e.g., "excessive spending, unhealthy habits, risky activities"]

**Ad Transparency:**
- Why am I seeing this ad? Minors can click "Why this ad?" to see: [EXPLANATION - e.g., "This ad is shown because you're watching a video about [topic], not because of your personal data"]

### Reporting Inappropriate Ads

**If you see an ad that shouldn't be shown to minors:**
1. Click [REPORT BUTTON - e.g., "three dots → Report Ad → Inappropriate for minors"]
2. We review within [TIMEFRAME - e.g., "24 hours"]
3. If inappropriate, we [ACTIONS - e.g., "remove ad, block advertiser, refine ad filters"]

---

## COMPONENT 5: Addictive Design Mitigation

**DSA Article 38(3): Assess and mitigate negative effects on mental health and well-being**

### Design Features Assessment

**We assess all features for potential to encourage excessive use:**

**Features That May Encourage Excessive Use:**

[BE HONEST - CHECK ALL THAT APPLY TO YOUR SERVICE:]

☐ **Autoplay:** Videos/content automatically plays next
☐ **Infinite Scroll:** Content feed never ends
☐ **Notifications:** Push notifications encourage return visits
☐ **Streaks:** Daily usage "streaks" that break if you don't return
☐ **Likes/Hearts:** Feedback loops that encourage posting for validation
☐ **Leaderboards:** Rankings that encourage competitive behavior
☐ **Rewards/Points:** Gamification that incentivizes time spent
☐ **Countdown Timers:** FOMO-inducing timers for limited offers/content

**Our Assessment:**
- [FEATURE] has [RISK LEVEL: High/Medium/Low] risk of excessive use
- Evidence: [DATA - e.g., "Users with autoplay enabled spend [X]% more time on platform"]

### Mitigations for Minors

**For users under 18, we mitigate addictive design:**

**Disabled by Default:**
☐ Autoplay: [OFF / ON WITH PROMPT]
☐ Push notifications: [OFF / LIMITED]
☐ Streaks: [DISABLED / NOT EMPHASIZED]

**Usage Time Tools:**
☐ **Screen Time Dashboard:** See daily/weekly usage at [LOCATION]
☐ **Time Limit Reminders:** After [DURATION - e.g., "60 minutes"], see reminder to take a break
☐ **Suggested Breaks:** Prompts to [ACTION - e.g., "close app, stretch, rest eyes"] every [INTERVAL]
☐ **Scheduled Quiet Time:** Set hours when app is [UNAVAILABLE / IN LIMITED MODE - e.g., "during school (8am-3pm), bedtime (10pm-7am)"]

**Parental Controls:**
☐ Parents can set [CONTROLS - e.g., "daily time limits, content restrictions, quiet hours"]
☐ Parents receive [REPORTS - e.g., "weekly screen time reports"]

**Mental Health Support:**
☐ In-app resources: [DESCRIBE - e.g., "Links to mental health hotlines, well-being tips"]
☐ Crisis intervention: If user searches for [KEYWORDS - e.g., "self-harm, suicide, eating disorder"], show [RESOURCES - e.g., "helpline numbers, crisis text lines"]

### What Minors Can Do

**Take Control of Your Experience:**

1. **Turn Off Autoplay:** [SETTINGS PATH]
2. **Disable Notifications:** [SETTINGS PATH]
3. **Set Time Limits:** [SETTINGS PATH]
4. **Take a Break:** Use [FEATURE - e.g., "'Pause' button to hide feed for 30min"]
5. **Ask for Help:** If you feel you're using [SERVICE] too much, talk to a parent or visit [SUPPORT URL]

---

## COMPONENT 6: Content Restrictions & Age-Appropriate Experiences

### Age-Appropriate Content

**Minors see a different experience:**

**Restricted Content (Hidden from Minors):**

☐ **Sexual Content:** Nudity, sexual acts, explicit language
☐ **Violence:** Graphic violence, gore, animal cruelty
☐ **Self-Harm:** Content promoting self-harm, suicide, eating disorders
☐ **Hate Speech:** Slurs, extremist content
☐ **Dangerous Activities:** Challenges encouraging risky behavior
☐ **Substance Use:** Drug use, excessive alcohol consumption
☐ **[OTHER RESTRICTED CONTENT]**

**How We Enforce:**

- **AI Content Classification:** All content scanned for [CONTENT TYPES] before visible to minors
- **Age Gates:** If content is flagged as adult, minors cannot access (even with parental permission)
- **Human Review:** Borderline content reviewed by moderators
- **Community Reports:** Minors can report content that shouldn't be visible to them

### Search & Discovery Restrictions

**For users under 18:**

- **Safe Search:** [ON BY DEFAULT / ALWAYS ON / CANNOT BE DISABLED]
- **Trending Content:** Minors see [AGE-APPROPRIATE / CURATED] trending content (not global trends)
- **Recommendations:** Our recommender systems prioritize [CRITERIA - e.g., "educational, creative, positive content"] for minors
- **Hashtag Restrictions:** [HASHTAGS - e.g., "#selfharm, #eatingdisorder, #drugs"] are [HIDDEN / SHOW WARNING / REDIRECT TO RESOURCES]

### Content Minors Can Create

**Posting Restrictions:**

[IF APPLICABLE:]

- Users under [AGE] can [VIEW ONLY / POST WITH RESTRICTIONS]
- Restrictions:
  - ☐ Posts reviewed before public (pre-moderation)
  - ☐ Posts default to [PRIVATE / FRIENDS ONLY]
  - ☐ Cannot post [CONTENT TYPES - e.g., "live video, location-tagged posts"]
  - ☐ Cannot use [FEATURES - e.g., "direct messaging with strangers, public comments"]

---

## COMPONENT 7: Privacy & Data Protection

**GDPR Article 8 + DSA Article 38: Minors have enhanced privacy protections**

### Data We Collect from Minors

**We collect the minimum data necessary to provide [SERVICE NAME]:**

**Required Data:**
- [LIST - e.g., "Account information (username, birthdate, parent email if under 16)"]
- [USAGE DATA - e.g., "What you view, post, search for"]
- [TECHNICAL DATA - e.g., "Device type, IP address (country-level only)"]

**Data We DON'T Collect from Minors:**
- ❌ **Precise Location:** We only collect country, not exact location
- ❌ **Tracking Across Sites:** We don't track minors' activity outside [SERVICE NAME]
- ❌ **Third-Party Data:** We don't buy data about minors from data brokers
- ❌ **Contact Lists:** We don't access contacts (unless parent explicitly approves)

### How We Use Minor Data

**Permitted Uses:**
- ✅ Provide the service (show requested content, enable posting)
- ✅ Safety (detect abuse, illegal content, predatory behavior)
- ✅ Required by law (report CSAM, respond to legal orders)
- ✅ Parental controls (show usage data to parents of under-16s)

**Prohibited Uses:**
- ❌ **Advertising Profiling:** No behavioral advertising targeting minors
- ❌ **Selling Data:** We NEVER sell minor data
- ❌ **Sharing with Third Parties:** Except [EXCEPTIONS - e.g., "safety partners (NCMEC for CSAM), law enforcement with legal basis"]

### Privacy Settings for Minors

**Default Privacy (Cannot Be Weakened):**

- **Account Privacy:** [PRIVATE BY DEFAULT / PUBLIC WITH RESTRICTIONS]
- **Who Can See Posts:** [FRIENDS ONLY / FOLLOWERS ONLY / NO PUBLIC POSTS]
- **Who Can Contact Me:** [FRIENDS ONLY / NO STRANGERS]
- **Profile Visibility:** [HIDDEN FROM SEARCH / LIMITED VISIBILITY]
- **Location Sharing:** [DISABLED / COUNTRY-ONLY]

**Minors CANNOT:**
- ❌ Make account fully public (if under [AGE])
- ❌ Allow DMs from anyone
- ❌ Share precise location

### Data Access & Deletion

**Minors (and Their Parents) Can:**

1. **View Data:** See all data we have about you at [URL]
2. **Download Data:** Export your data at [URL]
3. **Delete Data:** Request deletion at [URL]
   - **Timeframe:** Deleted within [DURATION - e.g., "30 days"]
   - **Exceptions:** Data we must keep for [REASONS - e.g., "legal compliance, safety investigations"]
4. **Correct Data:** Update incorrect information at [SETTINGS URL]

**When Minor Turns 18:**
- We ask if you want to [KEEP ACCOUNT / TRANSITION TO ADULT ACCOUNT / DELETE]
- Adult accounts have different privacy settings (you gain more control but lose some protections)

---

## COMPONENT 8: Contact Restrictions & Safety Features

### Who Can Contact Minors

**To prevent grooming and harassment:**

**Direct Messages (DMs):**
- **Users Under 16:** Can only DM [FRIENDS / MUTUAL FOLLOWERS / NO ONE]
- **Users 16-17:** Can only receive DMs from [FRIENDS / MUTUAL FOLLOWERS / ANYONE (with filter)]
- **Adults Messaging Minors:** Adults [CANNOT / CAN WITH RESTRICTIONS] message minors they don't know
  - If allowed: [RESTRICTIONS - e.g., "Limited to one message unless minor replies, content filtered for grooming language"]

**Comments:**
- **On Minor's Posts:** [FRIENDS ONLY / MUTUAL FOLLOWERS / ANYONE (with filter)]
- **Filter:** Comments from strangers are [HIDDEN BY DEFAULT / REQUIRE APPROVAL / SHOWN WITH WARNINGS]

**Live Interactions:**
- **Live Streaming:** Minors [CANNOT GO LIVE / CAN GO LIVE WITH RESTRICTIONS]
  - If allowed: [RESTRICTIONS - e.g., "Friends-only audience, comment moderation required, no gifts/donations"]
- **Video Calls:** Minors [CANNOT VIDEO CALL / CAN ONLY CALL FRIENDS]

### Safety Features for Minors

**Block & Mute:**
- Easy [ONE-CLICK / TWO-TAP] blocking at [LOCATION]
- Blocked users [CANNOT SEE PROFILE / CONTACT / FIND IN SEARCH]
- Muted users: [SEE THEIR CONTENT BUT DON'T GET NOTIFICATIONS]

**Comment Filtering:**
- **Automatic:** We hide comments containing [KEYWORDS - e.g., "profanity, sexual language, bullying terms"]
- **Custom:** Minors can add custom blocked words at [SETTINGS PATH]
- **Stranger Comments:** Comments from non-friends [REQUIRE APPROVAL / HIDDEN BY DEFAULT]

**Restricted Mode:**
- Activate "Safety Mode" at [SETTINGS PATH]
- Limits [FEATURES - e.g., "who can see you online, who can find your account, who can comment, notifications from strangers"]

### Warning Systems

**Predatory Behavior Detection:**

- **AI Detection:** We scan [CONTENT - e.g., "DMs, comments"] for grooming language patterns
- **Red Flags:** [EXAMPLES - e.g., "Age-focused questions, requests to move off-platform, gift offers, sexual content"]
- **Warnings:** If detected, we [ACTIONS]:
  - ☐ Warn minor: "This conversation may be unsafe"
  - ☐ Block message from being sent
  - ☐ Notify parent (for under-16s)
  - ☐ Report to our safety team for investigation
  - ☐ Report to [AUTHORITY - e.g., "NCMEC, local police"] if severe

**If You Feel Unsafe:**

1. **Block the person immediately**
2. **Don't respond** (engaging encourages them)
3. **Screenshot evidence** (for reporting)
4. **Report to us** (see Component 9)
5. **Tell a trusted adult** (parent, teacher, counselor)
6. **Call for help:** [HOTLINE - e.g., "Childline: 116 111"]

---

## COMPONENT 9: Reporting & Support

### How to Report Child Safety Issues

**What You Can Report:**

☐ **Child Sexual Abuse Material (CSAM)**
☐ **Grooming / Predatory Behavior**
☐ **Sextortion / Exploitation**
☐ **Bullying / Harassment**
☐ **Self-Harm / Suicide Content**
☐ **Age-Inappropriate Content Shown to Minors**
☐ **Minor Lying About Age**
☐ **Other Child Safety Concerns**

### How to Report

**Option 1: In-App Reporting (Fastest)**

1. Go to [CONTENT / PROFILE / MESSAGE]
2. Click [ICON - e.g., "three dots, flag icon"]
3. Select "Report"
4. Choose category: [CHILD SAFETY]
5. Provide details (what happened, why it's unsafe)
6. Submit

**Option 2: Report Form (For Complex Cases)**

- Visit: [URL - e.g., "service.com/report/child-safety"]
- Fill in: [FIELDS - e.g., "Your info, minor's info, description, evidence links, screenshots"]
- Submit

**Option 3: Email (For Emergencies)**

- Email: [CHILD-SAFETY-EMAIL - e.g., "childsafety@service.com"]
- Subject: "URGENT: Child Safety Report"
- Include: [DETAILS - e.g., "Account URLs, description, evidence"]

**Option 4: Child Safety Organizations (Anonymous)**

If you don't want to report to us directly, you can report to:

- **[COUNTRY]-Specific Hotlines:** [LIST BY EU COUNTRY]
- **INHOPE:** https://www.inhope.org (international hotline network)
- **NCMEC (US-based, global reach):** https://www.cybertipline.org

### What Happens After You Report

**Our Response:**

1. **Priority Review:** Child safety reports reviewed within [TIMEFRAME - e.g., "1 hour for CSAM/grooming, 24 hours for other issues"]
2. **Investigation:** Our team reviews the report, evidence, account history
3. **Action:** If violation confirmed:
   - ☐ Content removed immediately
   - ☐ Account suspended or terminated
   - ☐ Reported to law enforcement (CSAM, serious threats)
   - ☐ Reported to [ORG - e.g., "NCMEC"]
4. **Notification:**
   - ☐ Reporter notified of outcome (within [TIMEFRAME])
   - ☐ Affected user (if minor) and parents notified
5. **Appeal:** If you disagree with outcome, appeal at [URL]

**Legal Reporting:**

For certain illegal content, we are **required by law** to report to:
- **CSAM:** [ORGANIZATION - e.g., "NCMEC (US), IWF (UK), INHOPE (EU)"]
- **Serious Crimes:** [LAW ENFORCEMENT - e.g., "Local police, Europol"]

### Support Resources

**For Minors:**

- **Childline (EU):** 116 111 (free, 24/7, confidential)
- **Crisis Text Line:** [NUMBER / URL]
- **Mental Health Support:** [ORGANIZATIONS - e.g., "Mind, Young Minds, Samaritans"]
- **Bullying Support:** [ORGANIZATIONS - e.g., "Ditch the Label, Anti-Bullying Alliance"]

**For Parents:**

- **Internet Safety Guides:** [URL]
- **Talking to Your Child:** [URL - e.g., "How to discuss online safety"]
- **Parental Control Setup:** [URL]
- **What to Do If Your Child is Harmed:** [URL]

---

## COMPONENT 10: Enforcement & Updates

### Consequences for Violating Child Safety Rules

**Adults Who Target Minors:**

- **First Violation:** [CONSEQUENCE - e.g., "Immediate account termination"]
- **Reported to Law Enforcement:** [YES/NO, CRITERIA]
- **Permanent Ban:** [YES - cannot create new accounts]

**Minors Lying About Age:**

- **Under Minimum Age:** Account suspended until valid age verification provided (or permanently if under minimum age)
- **Falsely Claiming Adult Status:** Account corrected to minor status, restrictions applied

**Inappropriate Content Targeting Minors:**

- **Content Removed:** [TIMEFRAME]
- **Creator Penalties:** [ESCALATION - e.g., "Warning → suspension → termination"]

### Policy Updates

**We review this policy:**
- **Quarterly:** Scheduled reviews for improvements
- **When Features Change:** Any new feature assessed for child safety impact
- **When Regulations Update:** DSA guidance, national laws, court rulings

**You'll Be Notified:**
- Major changes: [METHOD - e.g., "Email to parents, in-app notification, 30-day notice"]
- Minor changes: [METHOD - e.g., "Updated effective date on policy page"]

**Questions or Concerns?**

- **Email:** [CHILD-SAFETY-EMAIL]
- **Help Center:** [URL]
- **Parent Support:** [URL]

---

## Template Notes for Compliance Teams

### DSA Article 38 Requirements Met

This template ensures compliance with all DSA Article 38 requirements:

1. ✅ **Age-Appropriate Design** (Sections 3, 5, 6)
2. ✅ **High Level of Privacy, Safety, Security** (Sections 7, 8)
3. ✅ **No Profiling-Based Advertising** (Section 4)
4. ✅ **Addictive Design Mitigation** (Section 5)
5. ✅ **Parental Controls** (Section 3)
6. ✅ **Risk Assessment** (See Articles 34-35 Template - Component 8)
7. ✅ **Reporting & Redress** (Section 9)

### Customization Guidelines

**For Different Service Types:**

- **Social Media:** Emphasize contact restrictions, privacy, addictive design
- **Video Platforms:** Focus on content restrictions, autoplay, recommended content
- **Gaming Platforms:** Highlight loot boxes, in-game purchases, chat safety
- **Marketplaces:** Address age verification for purchases, scam protection
- **Educational Services:** Lighter restrictions, focus on data protection

**Age-Gating Approaches:**

- **Strict (No Under-13s):** Most common (COPPA compliance)
- **Tiered (Different ages, different features):** E.g., 13-15 get X, 16-17 get Y
- **Parent-Controlled (Kids Mode):** Separate experience for young children with parent oversight

### Quality Assurance Checklist

Before publishing child safety policy:

- [ ] All [bracketed] fields filled in
- [ ] Age verification method specified and implemented
- [ ] Parental consent process (if service has under-16s) functional
- [ ] Advertising restrictions technically enforced (no profiling for minors)
- [ ] Addictive design features honestly assessed and mitigated
- [ ] Contact restrictions technically enforced
- [ ] Privacy-by-design implemented (data minimization)
- [ ] Reporting mechanism easy to find and use
- [ ] Support resources included (hotlines, crisis support)
- [ ] Legal review completed (GDPR, DSA, national child safety laws)
- [ ] Child safety expert review completed
- [ ] Language appropriate for parents AND teens
- [ ] Translated to all 24 EU languages

### Common Mistakes to Avoid

❌ **Don't:** Say "we take child safety seriously" without specifics
✅ **Do:** List concrete measures with technical details

❌ **Don't:** Hide age verification weaknesses
✅ **Do:** Be honest about limitations (e.g., "self-reported age can be lied about")

❌ **Don't:** Use vague language like "age-appropriate content"
✅ **Do:** Specify exactly what content is restricted and how

❌ **Don't:** Forget to explain WHY each protection exists
✅ **Do:** Help parents and teens understand the risks you're mitigating

❌ **Don't:** Copy another platform's policy
✅ **Do:** Customize to YOUR service's specific features and risks

---

## EUR-Lex References

**Primary Regulation:**
- **EU Digital Services Act** (Regulation 2022/2065)
- **Full Regulation:** https://eur-lex.europa.eu/eli/reg/2022/2065

**DSA Article 38 - Protection of Minors:**
- **Article 38 Text:** https://eur-lex.europa.eu/eli/reg/2022/2065/oj#d1e4695-1-1
- **Article 38(1):** High level of privacy, safety, and security for minors
- **Article 38(2):** Prohibition on targeted advertising based on profiling of minors
- **Article 38(3):** Age-appropriate design and risk mitigation obligations

**Related DSA Articles:**
- **Articles 34-35:** Systemic risk assessment (minor protection is mandatory risk category) - https://eur-lex.europa.eu/eli/reg/2022/2065/oj#d1e4526-1-1

**Related EU Regulations:**
- **GDPR Article 8:** Conditions for child's consent (data processing) - https://eur-lex.europa.eu/eli/reg/2016/679/oj#d1e1796-1-1
- **ePrivacy Directive (2002/58/EC):** Privacy and electronic communications - https://eur-lex.europa.eu/eli/dir/2002/58/oj

**International Standards:**
- **UN Convention on Rights of the Child** - https://www.ohchr.org/en/instruments-mechanisms/instruments/convention-rights-child

---

**Template Version:** 1.0
**Created:** 2025-12-02
**Status:** Production-ready
**Maintained By:** DSA Compliance Team + Child Safety Experts
**Next Review:** Quarterly or upon feature changes
