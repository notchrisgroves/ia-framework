# DSA-Compliant Statement of Reasons Template
## Article 20: Content Moderation Decision Notifications

**Policy Type:** Statement of Reasons (Content Moderation Notices)
**DSA Article Covered:** Article 20
**Target Services:** All online platforms (including VLOP/VLOSE)
**Template Version:** 1.0
**Last Updated:** 2025-12-02

---

## How to Use This Template

1. **Use for EVERY content moderation decision** affecting content visibility or user accounts
2. **Fill in all [bracketed] fields** with case-specific information
3. **Keep all 8 required elements** - legally mandated by DSA Article 20
4. **Use plain language** - target Flesch-Kincaid grade level ≤10
5. **Send within required timeframes** - Immediately for removals, within 24h for restrictions
6. **Provide in user's language** - Use user's interface language preference
7. **Make accessible** - Text format, screen-reader compatible, WCAG compliant

**DSA Article 20 Requirements Checklist:**
- [ ] Decision type clearly stated (removal, restriction, suspension, etc.)
- [ ] Legal basis or Terms provision cited with specific reference
- [ ] Facts and circumstances explained (what was the violation)
- [ ] Automated means disclosed (if decision involved automation/AI)
- [ ] Redress options provided (internal appeal + out-of-court settlement)
- [ ] Plain language used (grade ≤10)
- [ ] Delivered to user promptly (immediately for removal, 24h for restriction)
- [ ] Accessible format (WCAG compliant)

---

# Statement of Reasons: Content Moderation Decision

**This notification explains why we took action on your content or account.**

---

## COMPONENT 1: Header & Metadata

**From:** [SERVICE NAME] Trust & Safety Team

**To:** [USER DISPLAY NAME / USERNAME]

**Date:** [DATE AND TIME - e.g., December 2, 2025, 14:35 UTC]

**Case Reference Number:** [UNIQUE ID - e.g., TAS-2025-12-45678]

**Decision Type:** [SELECT: Content Removal / Content Restriction / Account Suspension / Account Termination / Visibility Limitation / Monetization Suspension / Feature Restriction]

**Content Affected:**
- **Content Type:** [SELECT: Post / Comment / Review / Video / Image / Profile / Listing / Ad / Other]
- **Content ID:** [INTERNAL ID - for tracking]
- **Posted Date:** [DATE]
- **Content URL:** [URL if publicly accessible before removal]

**Service:** [SERVICE NAME - e.g., Google Play, YouTube, Facebook]

**User Account:** [USERNAME / USER ID]

---

## COMPONENT 2: Decision Summary (What Happened)

### What We Did

We have taken the following action on your [content/account]:

**Action Taken:** [CLEAR DESCRIPTION]

[SELECT ONE OR MORE:]

☐ **Content Removed:** Your [post/video/comment/review] has been permanently removed from [SERVICE NAME].

☐ **Content Restricted:** Your [content type] is no longer visible to [specific audience - e.g., "all users," "users under 18," "users in specific countries"].

☐ **Account Suspended:** Your account has been temporarily suspended for [DURATION - e.g., 7 days, 30 days].

☐ **Account Terminated:** Your account has been permanently closed.

☐ **Visibility Limited:** Your [content type] now has limited visibility and will not appear in [recommendations/search/feeds].

☐ **Monetization Suspended:** Your ability to earn revenue has been suspended for [DURATION].

☐ **Feature Restricted:** You can no longer use [SPECIFIC FEATURE - e.g., "post comments," "upload videos," "send messages"] for [DURATION or "indefinitely"].

### When This Takes Effect

This decision is effective **immediately** / **as of [DATE AND TIME]**.

### What This Means for You

[EXPLAIN PRACTICAL IMPACT IN PLAIN LANGUAGE]

**Example - Content Removal:**
"Your review posted on December 1, 2025, is no longer visible on Google Play. Other users cannot see it, and it will not appear in app ratings or search results."

**Example - Account Suspension:**
"You cannot access your YouTube account until January 10, 2026. You cannot upload videos, post comments, or view your subscriptions during this time."

---

## COMPONENT 3: Legal Basis (Why We Can Do This)

### The Rule You Violated

Your [content/account activity] violated the following rule:

**Legal Basis:** [SELECT ONE OR MORE:]

☐ **EU or National Law:**
   - **Law:** [SPECIFIC LAW - e.g., "German Network Enforcement Act (NetzDG)," "EU Copyright Directive Article 17"]
   - **Provision:** [SPECIFIC ARTICLE/SECTION]
   - **EUR-Lex / Official Reference:** [CITATION if EU law]

☐ **Our Terms of Service:**
   - **Policy:** [SERVICE NAME] Terms of Service, [EU Version / DSA-Compliant Version]
   - **Section:** [SPECIFIC SECTION - e.g., "Section 4.2: Prohibited Content - Hate Speech"]
   - **Rule:** [QUOTE THE EXACT RULE]

   **Example:**
   "Section 4.2 states: 'Content that promotes violence or hatred against individuals or groups based on race, ethnicity, religion, disability, gender, age, veteran status, or sexual orientation/gender identity is prohibited.'"

☐ **Community Guidelines:**
   - **Policy:** [SERVICE NAME] Community Guidelines
   - **Section:** [SPECIFIC SECTION - e.g., "Harassment and Bullying"]
   - **URL:** [DIRECT LINK TO SPECIFIC SECTION]

### Where to Read the Full Rule

You can read the complete policy here:
- **Terms of Service:** [URL]
- **Community Guidelines:** [URL]
- **Specific Section:** [DIRECT LINK TO VIOLATED SECTION]

---

## COMPONENT 4: Facts & Circumstances (What You Did)

### What Happened

We determined that your [content/activity] violated our policies based on the following:

**The Content/Activity:**

[DESCRIBE WHAT THE USER DID - Be specific but avoid reproducing harmful content]

**Example - Hate Speech:**
"Your comment posted on December 1, 2025 at 10:22 UTC contained language that targeted individuals based on their [protected characteristic]. Specifically, the comment included [general description without quoting harmful language, e.g., 'derogatory terms referring to a religious group']."

**Example - Copyright Violation:**
"Your video uploaded on November 28, 2025, contained copyrighted music owned by [Copyright Holder]. The content matched [specific copyrighted work] for [duration] of your [length] video."

**Example - Spam:**
"Your account posted [NUMBER] identical comments across [NUMBER] different posts within [TIME PERIOD], which violates our spam policies."

**Example - Illegal Product:**
"Your product listing offered [PRODUCT TYPE] for sale, which is prohibited under [EU REGULATION / NATIONAL LAW]. The listing description stated [relevant quote from listing]."

### Why This Violates Our Policies

[EXPLAIN THE CONNECTION BETWEEN USER'S ACTION AND THE RULE]

**Example - Hate Speech:**
"This language promotes hatred against a group based on their religion, which is prohibited under Section 4.2 of our Terms of Service and violates EU law on illegal hate speech."

**Example - Copyright:**
"Using copyrighted music without authorization violates copyright law and our Terms of Service Section 6.3, which requires you to have rights to all content you upload."

### Context Considered

[IF RELEVANT - What context was considered in the decision]

**Example:**
"We reviewed your account history and noted this is your [first/second/third] violation of this policy. We considered [any relevant context, such as 'whether the content was newsworthy,' 'whether it was clearly satirical,' 'whether it was educational']."

---

## COMPONENT 5: Automated Means Disclosure (How We Detected This)

### Detection Method

[REQUIRED BY DSA ARTICLE 20(3) - Explain if automated tools were used]

☐ **Human Review Only:**
This decision was made entirely by a human moderator who reviewed your content and applied our policies.

☐ **Automated Detection + Human Review:**
- **Initial Detection:** Your content was flagged by our automated content moderation system
- **Automated Tool Used:** [TOOL NAME/TYPE - e.g., "AI-based image classifier," "Keyword detection system," "AudioMatch copyright detection"]
- **What the Tool Does:** [PLAIN LANGUAGE EXPLANATION - e.g., "This tool scans images to detect prohibited content types"]
- **Human Review:** A human moderator reviewed the automated flag and made the final decision to [remove/restrict] your content
- **Human Decision:** The moderator [agreed/disagreed] with the automated system's recommendation

☐ **Fully Automated Decision:**
- **Automated Tool Used:** [TOOL NAME/TYPE]
- **What the Tool Does:** [EXPLANATION]
- **Why Automated:** [REASON - e.g., "Copyright matches are processed automatically to comply with legal requirements"]
- **Confidence Level:** [IF AVAILABLE - e.g., "99.2% match to copyrighted content"]
- **Human Review Available:** You can request human review through the appeal process (see Section 6 below)

### Accuracy Information

[IF AUTOMATED TOOLS USED - Provide transparency about accuracy]

**Example - Copyright Detection:**
"Our copyright detection system has a [X%] accuracy rate for [content type]. False positives occur in [X%] of cases. If you believe this is an error, please file an appeal."

**Example - CSAM Detection:**
"Our child safety systems use [TOOL NAME, e.g., PhotoDNA] to detect illegal content. This tool has been validated by [ORGANIZATION] and has a false positive rate of less than 0.01%."

---

## COMPONENT 6: Redress Options (How to Appeal)

### If You Disagree With This Decision

You have the right to challenge this decision. You have **two options**:

---

### OPTION 1: Internal Appeal (Through [SERVICE NAME])

**How to File an Appeal:**

1. **Click this link:** [DIRECT APPEAL URL]
2. **Or log in to your account** and go to: [ACCOUNT SETTINGS] → [APPEALS / HELP CENTER] → [SUBMIT APPEAL]
3. **Provide your case reference number:** [CASE ID]
4. **Explain why you believe this decision is wrong**
5. **Submit within [TIMEFRAME - e.g., "6 months of receiving this notice"]**

**What Happens Next:**

- **Review Time:** We will review your appeal within [TIMEFRAME - e.g., "7 days" for most cases, "24 hours" for time-sensitive content]
- **Reviewer:** A different moderator (not the one who made the original decision) will review your appeal
- **Decision:** We will notify you of our decision via email and in your account
- **Possible Outcomes:**
  - **Appeal Granted:** We reverse our decision and restore your [content/account/access]
  - **Appeal Denied:** We uphold our original decision and provide additional explanation

**No Cost:** Internal appeals are free.

---

### OPTION 2: Out-of-Court Dispute Settlement

If our internal appeal does not resolve the issue, you can use an independent dispute resolution body.

**Certified Bodies We Work With:**

[LIST ALL CERTIFIED OUT-OF-COURT DISPUTE SETTLEMENT BODIES - DSA Article 21]

1. **[BODY NAME 1]**
   - **Website:** [URL]
   - **Email:** [EMAIL]
   - **Languages:** [LANGUAGES SUPPORTED]
   - **Fee:** [FREE or COST]
   - **Specialization:** [CONTENT TYPES - e.g., "All content types"]

2. **[BODY NAME 2]**
   - **Website:** [URL]
   - **Email:** [EMAIL]
   - **Languages:** [LANGUAGES SUPPORTED]
   - **Fee:** [FREE or COST]
   - **Specialization:** [CONTENT TYPES - e.g., "Copyright disputes"]

**How It Works:**

1. **Contact the dispute body** using the information above
2. **Provide your case reference number:** [CASE ID]
3. **The body will review** your case independently
4. **We are bound by their decision** in most cases (exceptions apply for illegal content)

**Timeframe:** Most out-of-court bodies resolve cases within [TIMEFRAME - e.g., "90 days"].

---

### OPTION 3: Legal Action

You also have the right to seek redress before the courts in accordance with applicable law.

**Where to File:**
- **Your Local Courts:** You may file a claim in the courts of the EU member state where you reside
- **Our Legal Entity:** [COMPANY LEGAL NAME], [REGISTERED ADDRESS], [COUNTRY]

**Limitation Period:** [TIMEFRAME - e.g., "You must file within 2 years of receiving this notice, or as provided by national law"]

---

## COMPONENT 7: Additional Information

### Content Backup (If Content Removed)

[IF APPLICABLE]

☐ **Content Deleted Immediately:** Your content has been permanently deleted and cannot be recovered.

☐ **Content Available for Download:** You can download a copy of your removed content for [DURATION - e.g., "30 days"] at: [DOWNLOAD URL]

☐ **Content in Account Archive:** Your content is included in your account data export, available at: [DATA EXPORT URL]

### Account Reinstatement (If Account Suspended)

[IF APPLICABLE]

Your account will be automatically reinstated on [DATE] if:
- ☐ You do not violate any policies during the suspension period
- ☐ You complete [REQUIRED ACTION - e.g., "age verification," "identity verification," "terms acknowledgment"]

**To Reinstate Early:** [IF APPLICABLE - Process for early reinstatement]

### Repeat Violations

[IF APPLICABLE]

This is your [FIRST / SECOND / THIRD+] violation of this policy.

**Our Repeat Violation Policy:**
- **First Violation:** [CONSEQUENCE - e.g., "Warning"]
- **Second Violation:** [CONSEQUENCE - e.g., "7-day suspension"]
- **Third Violation:** [CONSEQUENCE - e.g., "30-day suspension"]
- **Fourth+ Violation:** [CONSEQUENCE - e.g., "Permanent account termination"]

### Legal Reporting (If Illegal Content)

[IF CONTENT VIOLATES EU OR NATIONAL LAW]

☐ We are required by law to report certain illegal content to law enforcement.

**Reported To:** [LAW ENFORCEMENT AGENCY - e.g., "National Police / INTERPOL / Europol"]

**Reason:** [TYPE OF ILLEGAL CONTENT - e.g., "Child sexual abuse material," "Terrorist content," "Serious criminal activity"]

**Legal Basis:** [LAW REQUIRING REPORTING - e.g., "EU Regulation 2021/1232 (Terrorist Content Regulation)," "National CSAM reporting law"]

---

## COMPONENT 8: Contact & Support

### Questions About This Decision?

**Help Center:** [URL]
- Explanation of our policies
- Step-by-step appeal instructions
- Frequently asked questions

**Support Contact:**

- **Email:** [SUPPORT EMAIL - e.g., appeals@service.com]
- **Support Portal:** [URL]
- **Phone:** [PHONE NUMBER if available] ([HOURS] [TIME ZONE])
- **Response Time:** We typically respond within [TIMEFRAME - e.g., "48 hours"]

**When Contacting Us, Please Include:**
- Your case reference number: [CASE ID]
- Your username: [USERNAME]
- Clear explanation of your question or concern

### Language Support

This notice is available in the following languages:
[LIST IF MULTI-LANGUAGE SUPPORT AVAILABLE]

To receive this notice in another language: [INSTRUCTIONS]

### Accessibility

If you need this information in an alternative format (audio, large print, etc.), please contact: [ACCESSIBILITY EMAIL]

---

## Template Notes for Compliance Teams

### Required by DSA Article 20

This template includes all 8 elements required by DSA Article 20(1):

1. ✅ **Decision Type** - Component 2
2. ✅ **Legal Basis** - Component 3 (Terms provision or illegal content reference)
3. ✅ **Facts & Circumstances** - Component 4 (Why this specific content/activity violated)
4. ✅ **Automated Means Disclosure** - Component 5 (If AI/automation was used)
5. ✅ **Redress Options** - Component 6 (Internal appeal + out-of-court settlement + courts)
6. ✅ **Additional Information** - Component 7 (Case-specific details)
7. ✅ **Plain Language** - Entire template (grade level ≤10)
8. ✅ **Accessible Format** - Text-based, WCAG compliant

### Customization Guidelines

**For Different Decision Types:**

- **Content Removal:** Use all components, emphasize backup/download options
- **Content Restriction:** Explain what "restricted" means for this case (age-gated? geo-blocked? demonetized?)
- **Account Suspension:** Include reinstatement date, conditions, what user cannot do
- **Account Termination:** Emphasize finality, data export options, new account restrictions
- **Visibility Limitation:** Explain exactly where content will/won't appear

**For Different Violation Types:**

- **Illegal Content:** Include legal reporting (Component 7), cite specific laws
- **Terms Violations:** Quote exact Terms section, provide direct link
- **Copyright:** Include copyright holder info, DMCA process if applicable
- **Spam/Abuse:** Include volume/frequency data, explain pattern detected

**For Automated Decisions:**

- **Mandatory:** Describe tool used, what it does, accuracy information
- **Required:** Offer human review through appeal process
- **Best Practice:** Include confidence score if available

### Quality Assurance Checklist

Before sending any Statement of Reasons, verify:

- [ ] All [bracketed] fields filled in
- [ ] Case reference number is unique and trackable
- [ ] Legal basis is specific (not generic "violated terms")
- [ ] Facts are specific to this case (not template boilerplate)
- [ ] Automated means disclosed if any automation used
- [ ] All 3 redress options provided (internal, out-of-court, legal)
- [ ] Out-of-court body information is current and accurate
- [ ] Plain language used (no legal jargon without explanation)
- [ ] Readability: Flesch-Kincaid grade level ≤10
- [ ] Sent within required timeframe (immediately for removal)
- [ ] Accessible format (text, screen-reader compatible)
- [ ] User's language preference used (if available)

### Storage & Recordkeeping

**Required by DSA Article 24 (Transparency Reporting):**

- Store all Statements of Reasons for [DURATION - recommend: 6 months minimum]
- Track metrics: Total sent, by decision type, by policy violated
- Report publicly: Aggregate statistics (DSA Article 24 transparency reports)
- Provide to regulators on request

### Common Mistakes to Avoid

❌ **Don't:** Use generic boilerplate ("You violated our terms")
✅ **Do:** Cite specific policy section and explain how this content violated it

❌ **Don't:** Reproduce harmful content in the notice
✅ **Do:** Describe the content sufficiently without repeating harmful language

❌ **Don't:** Say "automated decision" without offering human review
✅ **Do:** Always offer appeal with human review for automated decisions

❌ **Don't:** Forget to disclose automation was used
✅ **Do:** Be transparent if AI/automation flagged or decided

❌ **Don't:** Provide only internal appeal option
✅ **Do:** Include out-of-court dispute settlement bodies

---

## EUR-Lex References

**Primary Regulation:**
- **EU Digital Services Act** (Regulation 2022/2065)
- **Full Regulation:** https://eur-lex.europa.eu/eli/reg/2022/2065

**DSA Article 20 - Statement of Reasons:**
- **Article 20 Text:** https://eur-lex.europa.eu/eli/reg/2022/2065/oj#d1e3212-1-1
- **Article 20(1):** Eight mandatory elements for all content moderation decisions
- **Article 20(2):** Proportionality requirement for restrictions
- **Article 20(3):** Automated decision-making disclosure obligation
- **Article 20(4):** Accessibility requirements for notifications

**Related DSA Articles:**
- **Article 21:** Out-of-court dispute settlement - https://eur-lex.europa.eu/eli/reg/2022/2065/oj#d1e3283-1-1
- **Article 22:** Internal complaint-handling systems - https://eur-lex.europa.eu/eli/reg/2022/2065/oj#d1e3375-1-1
- **Article 24:** Transparency reporting obligations - https://eur-lex.europa.eu/eli/reg/2022/2065/oj#d1e3511-1-1

---

**Template Version:** 1.0
**Created:** 2025-12-02
**Status:** Production-ready
**Maintained By:** DSA Compliance Team
**Next Review:** Quarterly or upon DSA guidance updates
