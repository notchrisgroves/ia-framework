---
name: code-review
description: Security-focused code review for vulnerability detection
---

# /code-review - Security Code Review

Security-focused code analysis with prompt-chained workflow enforcement.

**Agent:** security
**Skill:** code-review
**Output:** `output/engagements/code-reviews/{project}-{YYYY-MM}/`

---

## ğŸš¨ WORKFLOW ENFORCEMENT

**This command uses prompt chaining with mandatory gates.**

**You MUST:**
1. Load `commands/code-review/00-WORKFLOW.md` to determine current phase
2. Execute ONLY the current phase prompt
3. Verify gate before proceeding to next phase
4. Use WHAT/WHY/HOW for EVERY finding

**NEVER skip WHAT/WHY/HOW. NEVER omit CWE classification.**

---

## Phase Overview

```
Phase 1: ANALYZE â†’ Gate: All code scanned, vulns identified
Phase 2: DOCUMENT â†’ Gate: ALL findings have WHAT/WHY/HOW + CWE
Phase 3: DELIVER â†’ Gate: Complete report with remediation guide
```

**Prompts:** `commands/code-review/prompts/01-03-*.md`

---

## Quick Start

```
/code-review
```

**To start:**
1. Read `00-WORKFLOW.md` for phase detection logic
2. Identify code source and language
3. Load appropriate phase prompt from `prompts/`
4. Execute phase, verify gate, proceed

---

## When to Use

âœ… **Use /code-review when:**
- Identify security vulnerabilities in source code
- Validate secure coding practices (OWASP, CWE)
- Review code before production deployment
- Assess third-party or open-source code security
- Prepare for security audits or compliance reviews
- Train developers on secure coding patterns

âŒ **Don't use if:**
- Need runtime vulnerability scanning â†’ use `/vuln-scan`
- Need architecture-level review â†’ use `/arch-review`
- Need dependency vulnerability analysis â†’ use `/dependency-audit`

---

## Workflow

1. **Context Collection** - Prompts gather code location, language, review focus
2. **Analysis** - Static code analysis for security vulnerabilities
3. **Findings** - Categorize issues by severity, map to CWE/OWASP
4. **Output** - Generate review report in `output/engagements/code-reviews/{project}-{YYYY-MM}/`

**Estimated time:** 30-90 minutes

---

## Context Prompts

### Code Source

**Question:** "How will you provide the code to review?"

**Options:**
- **Directory Path** - Path to local codebase directory (recursive scan)
- **Specific Files** - List of specific file paths (targeted reviews)
- **Git Repository** - Clone from Git URL (public repos only)
- **Code Snippet** - Paste code directly (quick review)

**Default:** Directory Path

---

### Programming Language

**Question:** "What programming language(s) are you reviewing?"

**Options:**
- **Auto-Detect** - Agent detects languages from file extensions
- **JavaScript/TypeScript** - XSS, prototype pollution, injection
- **Python** - Injection, deserialization, insecure crypto
- **Java/C#** - Injection, XXE, deserialization
- **C/C++** - Buffer overflows, use-after-free, format strings
- **Go/Rust** - Concurrency, unsafe code, crypto misuse

**Multiple selection:** Yes

**Default:** Auto-Detect

---

### Review Depth

**Question:** "How thorough should the security review be?"

**Options:**
- **Quick Scan** - Automated static analysis (15-30 min), obvious vulnerabilities
- **Standard Review** - Balanced analysis with manual validation (45-60 min), OWASP Top 10
- **Deep Review** - Comprehensive manual review with threat modeling (90-120 min), logic flaws

**Default:** Standard Review

---

### Review Focus

**Question:** "What security areas should the review emphasize?"

**Options:**
- **OWASP Top 10** - Web application vulnerabilities (injection, broken auth, XSS)
- **CWE Top 25** - Most dangerous software weaknesses
- **Input Validation** - Injection flaws, sanitization, validation logic
- **Authentication/Authorization** - Access control, session management, privilege escalation
- **Cryptography** - Encryption, hashing, key management, random number generation
- **All Areas** - Comprehensive coverage (recommended)

**Multiple selection:** Yes

**Default:** OWASP Top 10

---

### Output Format

**Question:** "What output format do you need?"

**Options:**
- **Markdown Report** - Human-readable findings with code snippets, severity, remediation
- **SARIF** - Static Analysis Results Interchange Format (JSON) for tool integration
- **Both** - Generate both markdown and SARIF (recommended)

**Default:** Markdown Report

---

## Agent Routing

```typescript
// FLEXIBLE MODEL SELECTION (per library/model-selection-matrix.md):
//
// DEFAULT WORKFLOW: Sonnet executes, escalate strategically
//
// ULTRATHINK (Opus) - Strategic escalation points:
// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
// â”‚ â€¢ Review methodology design for complex codebases           â”‚
// â”‚ â€¢ Novel vulnerability discovery (beyond OWASP/CWE)          â”‚
// â”‚ â€¢ Business logic flaw analysis                              â”‚
// â”‚ â€¢ When standard patterns don't explain the vulnerability    â”‚
// â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
//
// EXECUTION: Sonnet (pattern matching, OWASP/CWE detection, documentation)
// REASONING: Grok Code (WHY vulnerable - shows reasoning traces)
// QA/CHALLENGE: Grok (adversarial review - what did I miss?)
// VALIDATION: Haiku (format checks, quick syntax validation)

Task({
  subagent_type: "security",
  model: "sonnet",  // Default - escalate to opus/grok as needed
  prompt: `
Mode: code-review
Skill: code-review
Workflow: security-code-analysis

Context:
- Code Source: {directory|files|git-repo|snippet}
- Language: {auto|javascript|python|java|cpp|go|rust}
- Review Depth: {quick|standard|deep}
- Review Focus: {owasp|cwe|input-validation|auth|crypto|all}
- Output Format: {markdown|sarif|both}

FLEXIBLE MODEL ESCALATION:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ULTRATHINK (Opus) - Invoke for:                                 â”‚
â”‚ â€¢ Designing review approach for complex/unfamiliar codebases    â”‚
â”‚ â€¢ Novel vulnerability patterns (not in standard checklists)     â”‚
â”‚ â€¢ Business logic vulnerabilities (requires understanding flow)  â”‚
â”‚ â€¢ Multi-file attack chains (A calls B which enables C exploit)  â”‚
â”‚ â€¢ When stuck: "I found injection but something else is wrong"   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ EXECUTION (Sonnet) - Default for:                               â”‚
â”‚ â€¢ Standard OWASP Top 10 / CWE Top 25 pattern matching           â”‚
â”‚ â€¢ Known vulnerability detection (injection, XSS, auth flaws)    â”‚
â”‚ â€¢ Documentation and finding write-ups                           â”‚
â”‚ â€¢ Remediation guidance for known issues                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ REASONING (Grok Code) - Escalate for:                           â”‚
â”‚ â€¢ "WHY is this vulnerable?" - shows reasoning traces            â”‚
â”‚ â€¢ Complex injection paths needing step-by-step explanation      â”‚
â”‚ â€¢ Educational reviews (training developers on WHY not just WHAT)â”‚
â”‚ â€¢ When you need to EXPLAIN the vulnerability to stakeholders    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ QA/CHALLENGE (Grok) - Escalate for:                             â”‚
â”‚ â€¢ "What vulnerabilities did I miss?" adversarial review         â”‚
â”‚ â€¢ Second opinion on severity ratings                            â”‚
â”‚ â€¢ Challenge "this looks safe" assumptions                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ VALIDATION (Haiku) - Use for:                                   â”‚
â”‚ â€¢ Quick format/syntax checks                                    â”‚
â”‚ â€¢ SARIF output validation                                       â”‚
â”‚ â€¢ Checklist verification                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Instructions:
Execute code-review SKILL.md workflow:
1. Static code analysis for security vulnerabilities
2. Categorize issues by severity
3. Map to CWE/OWASP
4. Generate findings with remediation

Output: output/engagements/code-reviews/{project}-{YYYY-MM}/
`
})
```

---

## Output Structure

```
output/engagements/code-reviews/{project}-{YYYY-MM}/
â”œâ”€â”€ REVIEW-SUMMARY.md
â”œâ”€â”€ FINDINGS.md
â”œâ”€â”€ CODE-QUALITY.md
â”œâ”€â”€ REMEDIATION-GUIDE.md
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ findings.sarif
â”‚   â”œâ”€â”€ scan-logs/
â”‚   â””â”€â”€ code-snippets/
â””â”€â”€ session-state.md
```

**Deliverables:**

1. **Review Summary** - Overall security posture, critical findings count, top 5 risks, compliance status

2. **Findings** - Vulnerability details with severity, CWE/OWASP mapping, affected code location, code snippet, exploitation scenario, remediation

3. **Code Quality Assessment** - Secure coding practices score, anti-patterns, best practices adherence

4. **Remediation Guide** - Prioritized fix list (P0/P1/P2), code examples, testing guidance, timeline estimate

5. **SARIF Output** (if requested) - Machine-readable findings, GitHub Security compatible, IDE ready

---

## Examples

### Web Application Review

```
/code-review
â†’ Source: Directory | Language: JavaScript/TypeScript | Depth: Standard

Result: OWASP Top 10 analysis (~45-60 min)
Output: output/engagements/code-reviews/webapp-2025-12/
```

### Quick PR Scan (CI/CD)

```
/code-review
â†’ Source: Specific Files (5 changed) | Language: Python | Depth: Quick

Result: Fast security scan for PR checks (~10-15 min)
Output: SARIF format for automated pipeline
```

---

## Security Considerations

**Code Privacy:**
- Code stays local (not sent externally without permission)
- Sanitize findings before sharing
- Consider NDA and confidentiality requirements
- Use local-only tools for sensitive codebases

**Finding Disclosure:**
- Do not publish findings publicly without permission
- Follow coordinated disclosure timelines
- Report critical findings immediately
- Document remediation before public disclosure

**Tool Limitations:**
- Cannot detect all vulnerability classes
- May miss business logic flaws
- Runtime behavior not analyzed
- Complement with dynamic testing

---

## Related Commands

- `/arch-review` - Architecture-level security review
- `/dependency-audit` - Third-party dependency vulnerability analysis
- `/vuln-scan` - Runtime vulnerability scanning
- `/pentest` - Penetration testing with exploitation

---

## References

**Frameworks:**
- OWASP Top 10: owasp.org/www-project-top-ten
- CWE Top 25: cwe.mitre.org/top25
- SARIF: docs.oasis-open.org/sarif

**Secure Coding Guidelines:**
- OWASP Secure Coding Practices
- CERT Secure Coding Standards
- Language-specific security guides

---

**Version:** 1.0
**Last Updated:** 2025-12-12
**Framework:** Intelligence Adjacent (IA)
